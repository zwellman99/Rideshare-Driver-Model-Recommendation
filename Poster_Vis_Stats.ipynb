{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPDrCEo_Kkym"
      },
      "source": [
        "# Importing Data and Downloading Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1DsxyAfboPt",
        "outputId": "ab56abb1-9dfa-43c2-9ee7-757636682b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh73Qyh_b4Oy",
        "outputId": "a66c8e7d-152f-4e31-eb77-e1329b5e4a02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (from opendatasets) (1.5.13)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from opendatasets) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from opendatasets) (4.65.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle->opendatasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle->opendatasets) (1.26.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle->opendatasets) (2.27.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle->opendatasets) (2.0.12)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gfb9bEiyb2w8"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import folium\n",
        "from folium.plugins import HeatMap\n",
        "import itertools\n",
        "from prophet import Prophet\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import radians, sin, cos, sqrt, asin\n",
        "import pytz\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn import preprocessing\n",
        "from datetime import datetime\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.feature_selection import RFE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_LHlLR2b8W1",
        "outputId": "e17eec0e-efee-45d4-f13d-bb5b21072d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: blakeandersonw\n",
            "Your Kaggle Key: ··········\n",
            "Downloading uber-fares-dataset.zip to ./uber-fares-dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7.04M/7.04M [00:00<00:00, 141MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/yasserh/uber-fares-dataset\")\n",
        "os.chdir('/content/uber-fares-dataset')\n",
        "uber_df = pd.read_csv(\"uber.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sphibjvgcAO5"
      },
      "source": [
        "**username:** blakeandersonw\n",
        "\n",
        "**key:** 5c7b7542c5ad7af0d6015b98bfa868b4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "71edsvjbNcHw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5S0Li6ABNf8"
      },
      "source": [
        "Demand P2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIsV2bg4u8O-"
      },
      "source": [
        "# Demand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGDe9k-_cO8d"
      },
      "outputs": [],
      "source": [
        "uber_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoxD_L65vBSA"
      },
      "outputs": [],
      "source": [
        "# Assuming you've already loaded the dataset and processed the datetime column\n",
        "\n",
        "df = uber_df.copy()\n",
        "\n",
        "drop = [\"Unnamed: 0\", \"key\", \"fare_amount\", \"passenger_count\"]\n",
        "df.drop(drop, inplace=True, axis=1)\n",
        "\n",
        "# Create features for hour, day, day of the week, and month\n",
        "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
        "df['Hour'] = df['pickup_datetime'].dt.hour\n",
        "df['DayOfWeek'] = df['pickup_datetime'].dt.dayofweek\n",
        "df['Month'] = df['pickup_datetime'].dt.month\n",
        "df['Day'] = df['pickup_datetime'].dt.day\n",
        "df['HourGroup'] = df['Hour'] // 4\n",
        "\n",
        "# Create ride count per hour\n",
        "ride_counts = df.groupby(['HourGroup', 'DayOfWeek', 'Month', 'Day']).size().reset_index(name='RideCount')\n",
        "\n",
        "# Split the dataset into training, validation, and testing sets\n",
        "X = ride_counts[['HourGroup', 'DayOfWeek', 'Month', 'Day']]\n",
        "y = ride_counts['RideCount']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Train the models\n",
        "models = {'Linear Regression': LinearRegression(),\n",
        "          'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
        "          'Random Forest': RandomForestRegressor(random_state=42),\n",
        "          'XGBoost': XGBRegressor(random_state=42)}\n",
        "\n",
        "for name, demand_model in models.items():\n",
        "    demand_model.fit(X_train, y_train)\n",
        "    y_pred_val = demand_model.predict(X_val)\n",
        "    r2_val = r2_score(y_val, y_pred_val)\n",
        "    print(f\"{name} R-squared (Validation): {r2_val:.4f}\")\n",
        "\n",
        "print(\"Results on test set:\")\n",
        "for name, demand_model in models.items():\n",
        "    y_test_pred = demand_model.predict(X_test)\n",
        "    r2_test = r2_score(y_test, y_test_pred)\n",
        "    print(f\"{name} R-squared: {r2_test:.4f}\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.bar(models.keys(), [r2_score(y_test, model.predict(X_test)) for model in models.values()])\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('R-squared')\n",
        "ax.set_title('Predictive Power of Different Machine Learning Models on Demand')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['passenger_count', 'hour', 'day', 'month', 'distance']]\n",
        "y = df['fare_amount']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the models\n",
        "models = {'Linear Regression': LinearRegression(),\n",
        "          'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
        "          'Random Forest': RandomForestRegressor(random_state=42),\n",
        "          'XGBoost': XGBRegressor(random_state=42)}\n",
        "\n",
        "for name, revenue_model in models.items():\n",
        "    revenue_model.fit(X_train, y_train)\n",
        "    y_pred = revenue_model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"{name} R-squared: {r2:.4f}\")\n",
        "\n",
        "# Plot the results\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.bar(models.keys(), [r2_score(y_test, model.predict(X_test)) for model in models.values()])\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('R-squared')\n",
        "ax.set_title('Predictive Power of Different Machine Learning Models')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3PFmayxiKdg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ol3Jklym3bdO"
      },
      "outputs": [],
      "source": [
        "demand_model = XGBRegressor(random_state=42)\n",
        "demand_model.fit(X_train, y_train)\n",
        "\n",
        "def predict_ride_count(hourgroup, day_of_week, month, day):\n",
        "    # Create a dataframe with the input values\n",
        "    input_df = pd.DataFrame({\n",
        "        'HourGroup': [hourgroup],\n",
        "        'DayOfWeek': [day_of_week],\n",
        "        'Month': [month],\n",
        "        'Day': [day]\n",
        "    })\n",
        "\n",
        "    # Use the XGBoost model to make a prediction\n",
        "    prediction = demand_model.predict(input_df)[0]\n",
        "\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "for row in X_test.itertuples():\n",
        "    y_pred.append(predict_ride_count(row.HourGroup, row.DayOfWeek, row.Month, row.Day))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.2)\n",
        "plt.xlabel(\"Actual Ride Count\")\n",
        "plt.ylabel(\"Predicted Ride Count\")\n",
        "plt.title(\"Predicted versus Actual Ride Counts\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MQ0Akf-aSFPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(np.array(y_pred) - np.array(y_test), bins=100)\n",
        "plt.xlabel(\"Difference between Predicted and Actual Ride Counts\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Prediction Errors\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JSYfVkISSIXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(y_pred - y_test, bins=100)\n",
        "plt.xlabel(\"Difference between Predicted and Actual Fare Amounts\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Prediction Errors\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ytKLq8Z-Wg-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = y_test - y_pred\n",
        "sns.scatterplot(x=y_pred, y=residuals)\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel('Fitted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals vs. Fitted Values')\n"
      ],
      "metadata": {
        "id": "w_WvK2LmSKEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(residuals, shade=True)\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Density Plot of Residuals')\n"
      ],
      "metadata": {
        "id": "DCyAjBbKSKcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval = X_test.copy()\n",
        "df_eval['Actual Ride Count'] = y_test\n",
        "df_eval['Predicted Ride Count'] = y_pred\n",
        "df_eval['HourGroup'] = df_eval['HourGroup'].apply(lambda x: str(x) + ':00 - ' + str(x+3) + ':59')\n",
        "sns.boxplot(x='HourGroup', y='Ride Count', hue='Type', data=pd.melt(df_eval, id_vars=['HourGroup'], value_vars=['Actual Ride Count', 'Predicted Ride Count'], var_name='Type', value_name='Ride Count'))\n",
        "plt.xlabel('Hour of Day')\n",
        "plt.ylabel('Ride Count')\n",
        "plt.title('Actual versus Predicted Ride Counts by Hour of Day')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nQEVn0KTSMOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe to hold the evaluation data\n",
        "df_eval = X_test.copy()\n",
        "df_eval['Actual Rides'] = y_test\n",
        "df_eval['Predicted Rides'] = y_pred\n",
        "\n",
        "# Define the order of days of the week\n",
        "day_order = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
        "\n",
        "# Plot actual versus predicted rides by day of the week\n",
        "day_names = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
        "df_eval['DayOfWeek'] = df_eval['DayOfWeek'].map(day_names)\n",
        "sns.boxplot(x='DayOfWeek', y='Rides', hue='Type', data=pd.melt(df_eval, id_vars=['DayOfWeek'], value_vars=['Actual Rides', 'Predicted Rides'], var_name='Type', value_name='Rides'), order=day_order)\n",
        "plt.xlabel('Day of Week')\n",
        "plt.ylabel('Number of Rides')\n",
        "plt.title('Actual versus Predicted Rides by Day of Week')\n",
        "plt.show()\n",
        "\n",
        "# Plot the average actual and predicted rides by day of the week\n",
        "df_eval.groupby('DayOfWeek')[['Actual Rides', 'Predicted Rides']].mean().loc[day_order].plot(kind='bar', figsize=(8, 6))\n",
        "plt.xlabel('Day of Week')\n",
        "plt.ylabel('Average Number of Rides')\n",
        "plt.title('Average Actual versus Predicted Rides by Day of Week')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R5bVoV26Ukfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, median_absolute_error\n",
        "\n",
        "def evaluate_predictions(demand_model, X_test, y_test):\n",
        "    # Use the model to make predictions on the test set\n",
        "\n",
        "\n",
        "    # Calculate the R-squared score\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate the mean absolute error\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    # Calculate the mean squared error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    # Calculate the root mean squared error\n",
        "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "    mdae = median_absolute_error(y_test, y_pred)\n",
        "    # Print the results\n",
        "    print(f\"R-squared score: {r2:.4f}\")\n",
        "    print(f\"Mean absolute error: {mae:.4f}\")\n",
        "    print(f\"Mean squared error: {mse:.4f}\")\n",
        "    print(f\"Root mean squared error: {rmse:.4f}\")\n",
        "    print(f\"MAPE: {mape:.4f}\")\n",
        "    print(f\"MDAE: {mdae:.4f}\")"
      ],
      "metadata": {
        "id": "4wJTMyoVVTjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_predictions(demand_model, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0299YZyVbqm",
        "outputId": "1d1ea281-7cb0-4d97-f0e2-01b425d7cc9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared score: 0.5131\n",
            "Mean absolute error: 4.1128\n",
            "Mean squared error: 30.5759\n",
            "Root mean squared error: 5.5295\n",
            "MAPE: 0.3804\n",
            "MDAPE: 3.1931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_predictions(predict_fare_amount, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbISrDhGfj0j",
        "outputId": "e9270129-3458-4cef-ab4c-414276d50e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared score: 0.5662\n",
            "Mean absolute error: 1.6933\n",
            "Mean squared error: 6.4336\n",
            "Root mean squared error: 2.5365\n",
            "MAPE: 0.1954\n",
            "MDAE: 1.1898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTHMtLYG8HXr"
      },
      "outputs": [],
      "source": [
        "ride_counts['Pred_RideCount'] = ride_counts.apply(lambda x: predict_ride_count(x['HourGroup'], x['DayOfWeek'], x['Month'], x['Day']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MF2IGC2F3sae"
      },
      "outputs": [],
      "source": [
        "plt.scatter(ride_counts['RideCount'], ride_counts['Pred_RideCount'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "def evaluate_predict_ride_count(hourgroup, day_of_week, month, day, X_test, y_test, demand_model):\n",
        "    # Make a prediction for the input values\n",
        "    prediction = predict_ride_count(hourgroup, day_of_week, month, day)\n",
        "\n",
        "    # Get the actual ride count from the test set\n",
        "    actual = y_test.iloc[X_test[(X_test['HourGroup'] == hourgroup) & \n",
        "                                (X_test['DayOfWeek'] == day_of_week) & \n",
        "                                (X_test['Month'] == month) & \n",
        "                                (X_test['Day'] == day)].index[0]]\n",
        "\n",
        "    # Calculate the mean absolute error and R-squared\n",
        "    mae = mean_absolute_error([actual], [prediction])\n",
        "    r2 = r2_score([actual], [prediction])\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Actual ride count: {actual:.4f}\")\n",
        "    print(f\"Predicted ride count: {prediction:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"R-squared: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "zkv_-Wng9al4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V7zJIw-ODiM"
      },
      "source": [
        "# Revenue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbklGnvhPyTZ"
      },
      "outputs": [],
      "source": [
        "df = uber_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def distance(longitude1, latitude1, longitude2, latitude2):\n",
        "    travel_dist = []\n",
        "    \n",
        "    for pos in range(len(longitude1)):\n",
        "        long1,lati1,long2,lati2 = map(radians,[longitude1[pos],latitude1[pos],longitude2[pos],latitude2[pos]])\n",
        "        dist_long = long2 - long1\n",
        "        dist_lati = lati2 - lati1\n",
        "        a = sin(dist_lati/2)**2 + cos(lati1) * cos(lati2) * sin(dist_long/2)**2\n",
        "        c = 2 * asin(sqrt(a))*6371\n",
        "        travel_dist.append(c)\n",
        "       \n",
        "    return travel_dist"
      ],
      "metadata": {
        "id": "ID-eu2UGXpEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['distance'] = distance(df['pickup_longitude'].to_numpy(),\n",
        "                                                df['pickup_latitude'].to_numpy(),\n",
        "                                                df['dropoff_longitude'].to_numpy(),\n",
        "                                                df['dropoff_latitude'].to_numpy()\n",
        "                                              )"
      ],
      "metadata": {
        "id": "tk4JgCipXrSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MocRd4JPkdM"
      },
      "outputs": [],
      "source": [
        "def haversine_distance(row):\n",
        "    \"\"\"\n",
        "    Calculate the great circle distance between two points\n",
        "    on the Earth (specified in decimal degrees)\n",
        "    \"\"\"\n",
        "    # unpack the values from the row\n",
        "    lat1, lon1, lat2, lon2 = row[['pickup_latitude', 'pickup_longitude',\n",
        "                                  'dropoff_latitude', 'dropoff_longitude']]\n",
        "    \n",
        "    # convert decimal degrees to radians\n",
        "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
        "\n",
        "    # Haversine formula\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
        "    c = 2 * asin(sqrt(a))\n",
        "    r = 6371 # Radius of earth in kilometers. Use 3959 for miles\n",
        "    return c * r\n",
        "\n",
        "# Apply the function to the DataFrame and assign the result to a new column\n",
        "df['distance'] = df.apply(haversine_distance, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the quantiles that correspond to the top 5% and bottom 5% of price values\n",
        "q_05 = df['fare_amount'].quantile(0.04)\n",
        "q_95 = df['fare_amount'].quantile(0.96)\n",
        "\n",
        "# Remove rows where price is outside of the top 5% and bottom 5% range\n",
        "df = df[(df['fare_amount'] >= q_05) & (df['fare_amount'] <= q_95)]\n",
        "\n",
        "q_05d = df['distance'].quantile(0.01)\n",
        "q_95d = df['distance'].quantile(0.905)\n",
        "df = df[(df['distance'] >= q_05d) & (df['distance'] <= q_95d)]"
      ],
      "metadata": {
        "id": "4kT-UOlRS2Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_05d"
      ],
      "metadata": {
        "id": "h71y34otU1Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlJPdEfQPiGn"
      },
      "outputs": [],
      "source": [
        "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime']).dt.tz_convert(pytz.timezone('US/Eastern'))\n",
        "df['hour'] = df['pickup_datetime'].dt.hour\n",
        "df['day'] = df['pickup_datetime'].dt.dayofweek\n",
        "df['month'] = df['pickup_datetime'].dt.month\n",
        "df['year'] = df['pickup_datetime'].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3Uqubf1Pfse"
      },
      "outputs": [],
      "source": [
        "# Replace null values with median integer for passenger_count, hour, day, and month\n",
        "df['passenger_count'] = df['passenger_count'].fillna(df['passenger_count'].median())\n",
        "df['hour'] = df['hour'].fillna(df['hour'].median())\n",
        "df['day'] = df['day'].fillna(df['day'].median())\n",
        "df['month'] = df['month'].fillna(df['month'].median())\n",
        "df['year'] = df['year'].fillna(df['year'].median())\n",
        "\n",
        "# Replace null values with the mean for distance\n",
        "df['distance'] = df['distance'].fillna(df['distance'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7OgNGyiPHTK"
      },
      "outputs": [],
      "source": [
        "X = df[['passenger_count', 'hour', 'day', 'month', 'distance', 'year']]\n",
        "y = df['fare_amount']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZfyo7Z-djXU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Separate the features and target variable\n",
        "X = df[['passenger_count', 'hour', 'day', 'month', 'distance']]\n",
        "y = df['fare_amount']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the models\n",
        "models = {'Linear Regression': LinearRegression(),\n",
        "          'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
        "          'Random Forest': RandomForestRegressor(random_state=42),\n",
        "          'XGBoost': XGBRegressor(random_state=42)}\n",
        "\n",
        "for name, revenue_model in models.items():\n",
        "    revenue_model.fit(X_train, y_train)\n",
        "    y_pred = revenue_model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    print(f\"{name} R-squared: {r2:.4f}, MAE: ${mae:.2f}\")\n",
        "    \n",
        "# Plot the results\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.bar(models.keys(), [r2_score(y_test, model.predict(X_test)) for model in models.values()])\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('R-squared')\n",
        "ax.set_title('Predictive Power of Different Machine Learning Models on Fare')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['passenger_count', 'hour', 'day', 'month', 'distance']]\n",
        "y = df['fare_amount']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "t4viUmSP6A2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Separate the features and target variable\n",
        "X = df[['passenger_count', 'hour', 'day', 'month', 'distance']]\n",
        "y = df['fare_amount']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the models\n",
        "models = {'Linear Regression': LinearRegression(),\n",
        "          'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
        "          'Random Forest': RandomForestRegressor(random_state=42),\n",
        "          'XGBoost': XGBRegressor(random_state=42)}\n",
        "\n",
        "for name, far_model in models.items():\n",
        "    far_model.fit(X_train, y_train)\n",
        "    y_pred = far_model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    print(f\"{name} R-squared: {r2:.4f}, MAE: ${mae:.2f}\")\n",
        "    \n",
        "# Plot the results\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.bar(models.keys(), [r2_score(y_test, model.predict(X_test)) for model in models.values()])\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('R-squared')\n",
        "ax.set_title('Predictive Power of Different Machine Learning Models on Fare')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0yNIR9isPLd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZTUsfPdOJFQ"
      },
      "outputs": [],
      "source": [
        "# Train the XGBoost model\n",
        "fare_model = xgb.XGBRegressor(random_state=42)\n",
        "fare_model.fit(X_train, y_train)\n",
        "\n",
        "# Save the XGBoost model to disk\n",
        "fare_model.save_model('xgb_model.bin')\n",
        "\n",
        "# Create a function that uses the saved model to predict fare amount\n",
        "def predict_fare_amount(passenger_count, hour, day_of_week, month, distance):\n",
        "    # Load the trained model from disk\n",
        "    fare_model = xgb.Booster()\n",
        "    fare_model.load_model('xgb_model.bin')\n",
        "\n",
        "    # Prepare the input data as a Pandas DataFrame\n",
        "    data = {'passenger_count': [passenger_count],\n",
        "            'hour': [hour],\n",
        "            'day_of_week': [day_of_week],\n",
        "            'month': [month],\n",
        "            'distance': [distance]}\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Use the trained model to make a prediction\n",
        "    prediction = fare_model.predict(xgb.DMatrix(df))[0]\n",
        "\n",
        "    # Return the predicted fare amount\n",
        "    return prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zyeHa_hUvij"
      },
      "outputs": [],
      "source": [
        "def ride_rev_model(passenger_count, hour, day, month, distance):\n",
        "  fare = predict_fare_amount(passenger_count, hour, day, month, distance)\n",
        "  exp_rev = .85*fare #Uber takes 25%, expected 10% tip\n",
        "  exp_cost = exp_driver_cost(distance)\n",
        "  exp_profit = exp_rev - exp_cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaWeV9exWK06"
      },
      "outputs": [],
      "source": [
        "predict_fare_amount(1,12,3,1,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJW9EzbWxVsI"
      },
      "outputs": [],
      "source": [
        "df.fare_amount.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHkks433Nn2R"
      },
      "outputs": [],
      "source": [
        "dropping = [\"pickup_datetime\", \"pickup_longitude\",\t\"pickup_latitude\",\t\"dropoff_longitude\",\"dropoff_latitude\",\"year\",\"Unnamed: 0\", \"key\"]\n",
        "test_df = df.copy()\n",
        "test_df = test_df.drop(dropping, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L11jZ2V6NkoL"
      },
      "outputs": [],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_outliers(df, fare_threshold, distance_threshold):\n",
        "    \"\"\"\n",
        "    Filters out all outliers from the given DataFrame based on the given threshold values for the fare amount and distance.\n",
        "    \"\"\"\n",
        "    # Filter the DataFrame for fares under the given threshold\n",
        "    filtered_df = df[df['fare_amount'] < fare_threshold]\n",
        "\n",
        "    # Filter the DataFrame for distances under the given threshold\n",
        "    filtered_df = filtered_df[filtered_df['distance'] < distance_threshold]\n",
        "\n",
        "    return filtered_df"
      ],
      "metadata": {
        "id": "YHskOie_3mCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = filter_outliers(test_df, 30, 10)"
      ],
      "metadata": {
        "id": "1NU9N_2U5FCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.reset_index()"
      ],
      "metadata": {
        "id": "YHS-EbXW5jCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "lCIVUXp02ZJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "import seaborn as sns\n",
        "# Get predictions for the test data\n",
        "y_pred = []\n",
        "for row in X_test.itertuples():\n",
        "    y_pred.append(predict_fare_amount(row.passenger_count, row.hour, row.day, row.month, row.distance))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SA4iS7FWR6Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval = X_test.copy()\n",
        "df_eval['Actual Fare'] = y_test\n",
        "df_eval['Predicted Fare'] = y_pred\n",
        "df_eval['Hour'] = df_eval['hour'].apply(lambda x: str(x) + ':00')\n",
        "\n",
        "\n",
        "\n",
        "sns.set(rc={'figure.figsize':(44,18)}) \n",
        "sns.boxplot(x='Hour', y='Fare', hue='Type', data=pd.melt(df_eval, id_vars=['Hour'], value_vars=['Actual Fare', 'Predicted Fare'], var_name='Type', value_name='Fare'), order=hour_order)\n",
        "plt.xlabel('Hour of Day')\n",
        "plt.ylabel('Fare Amount')\n",
        "plt.title('Actual versus Predicted Fares by Hour of Day')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EH0bE8E61Z3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(8,6)}) "
      ],
      "metadata": {
        "id": "CAmdM6YcP-Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the R2 score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R2 score:\", r2)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_percent_error(y_test, y_pred)\n",
        "print(\"MAE:\", mae)\n",
        "\n",
        "# Calculate the root mean squared error\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print(\"RMSE:\", rmse)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.2)\n",
        "plt.xlabel(\"Actual Fare Amount\")\n",
        "plt.ylabel(\"Predicted Fare Amount\")\n",
        "plt.title(\"Predicted versus Actual Fares\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(y_pred - y_test, bins=100)\n",
        "plt.xlabel(\"Difference between Predicted and Actual Fare Amounts\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Prediction Errors\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5OIfq_5d0UsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"distance\"].describe()"
      ],
      "metadata": {
        "id": "9N5kfetsUq0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the actual fare_amount to X_test\n",
        "X_test_with_fares = X_test.copy()\n",
        "X_test_with_fares['fare_amount'] = y_test\n",
        "\n",
        "# Make the scatterplot\n",
        "sns.scatterplot(x='distance', y='fare_amount', data=X_test_with_fares, alpha=0.2)\n",
        "sns.scatterplot(x='distance', y=y_pred, data=X_test, alpha=0.2)\n",
        "\n",
        "plt.xlabel(\"Distance (km)\")\n",
        "plt.ylabel(\"Fare Amount\")\n",
        "plt.title(\"Predicted versus Actual Fares by Distance\")\n",
        "plt.legend(labels=['Actual', 'Predicted'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "x1Y91tpF1-Zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval = X_test.copy()\n",
        "df_eval['Actual Fare'] = y_test\n",
        "df_eval['Predicted Fare'] = y_pred\n",
        "df_eval['Profit'] = df_eval['Predicted Fare'] - df_eval['Actual Fare']\n",
        "df_eval['Hour'] = df_eval['hour'].apply(lambda x: str((x % 12) or 12) + ':00 ' + ('AM' if x < 12 else 'PM') + ' - ' + str(((x+3) % 12) or 12) + ':59 ' + ('AM' if (x+3) < 12 else 'PM'))\n",
        "\n",
        "sns.barplot(x='Hour', y='Profit', data=df_eval)\n",
        "plt.xlabel('Hour of Day')\n",
        "plt.ylabel('Average Profit')\n",
        "plt.title('Average Profit by Hour of Day')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "H6krWzzE7J83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create a new DataFrame with the predicted and actual fares and hour of day\n",
        "df_eval = X_test.copy()\n",
        "df_eval['Actual Fare'] = y_test\n",
        "df_eval['Predicted Fare'] = y_pred\n",
        "df_eval['Hour'] = df_eval['hour'].apply(lambda x: str(x) + ':00')\n",
        "\n",
        "# Pivot the data to show predicted and actual fares by hour of day\n",
        "df_pivot = df_eval.pivot_table(values=['Actual Fare', 'Predicted Fare'], index='Hour', aggfunc='mean')\n",
        "\n",
        "# Create a line plot of predicted and actual fares by hour of day\n",
        "sns.lineplot(data=df_pivot)\n",
        "plt.xlabel('Hour of Day')\n",
        "plt.ylabel('Fare Amount')\n",
        "plt.title('Predicted versus Actual Fares by Hour of Day')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HU5l8998Adjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval = X_test.copy()\n",
        "df_eval['Actual Fare'] = y_test\n",
        "df_eval['Predicted Fare'] = y_pred\n",
        "df_eval['Profit'] = df_eval['Predicted Fare'] - df_eval['fare_amount']\n",
        "df_eval['Hour'] = df_eval['hour'].apply(lambda x: str(x) + ':00 - ' + str(x+3) + ':59')\n",
        "sns.barplot(x='Hour', y='Profit', data=df_eval)\n",
        "plt.xlabel('Hour of Day')\n",
        "plt.ylabel('Average Profit')\n",
        "plt.title('Average Profit by Hour of Day')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "f9TnYdx345nK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}